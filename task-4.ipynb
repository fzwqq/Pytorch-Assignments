{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToPILImage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create dataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToPILImage()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show = ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) #normalize\n",
    "# trainset\n",
    "trainset = tv.datasets.CIFAR10(\n",
    "    root = './data/',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, \n",
    "    batch_size = 4,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "# testset\n",
    "testset = tv.datasets.CIFAR10(\n",
    "    './data/',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = transform\n",
    ")\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset,\n",
    "    batch_size = 4,\n",
    "    shuffle = False,\n",
    "    num_workers = 2\n",
    ")\n",
    "# ??tv.datasets.CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane' , 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=50x50 at 0x11E684748>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data , label) = trainset[60]\n",
    "print(classes[label],label)\n",
    "show((data+1)/2).resize((50,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataiter = iter(trainloader)\n",
    "# images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reconstruct NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(16*5*5, 120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "#         forward funtion\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "net = Net()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters() , lr = 0.001 , momentum = 0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1000] loss: 2.304\n",
      "[1,  2000] loss: 2.304\n",
      "[1,  3000] loss: 2.304\n",
      "[1,  4000] loss: 2.304\n",
      "[1,  5000] loss: 2.304\n",
      "[1,  6000] loss: 2.303\n",
      "[1,  7000] loss: 2.303\n",
      "[1,  8000] loss: 2.304\n",
      "[1,  9000] loss: 2.304\n",
      "[1, 10000] loss: 2.304\n",
      "[1, 11000] loss: 2.304\n",
      "[1, 12000] loss: 2.304\n",
      "[2,  1000] loss: 2.304\n",
      "[2,  2000] loss: 2.305\n",
      "[2,  3000] loss: 2.304\n",
      "[2,  4000] loss: 2.303\n",
      "[2,  5000] loss: 2.305\n",
      "[2,  6000] loss: 2.303\n",
      "[2,  7000] loss: 2.305\n",
      "[2,  8000] loss: 2.303\n",
      "[2,  9000] loss: 2.304\n",
      "[2, 10000] loss: 2.303\n",
      "[2, 11000] loss: 2.304\n",
      "[2, 12000] loss: 2.303\n"
     ]
    }
   ],
   "source": [
    "torch.set_num_threads(8)\n",
    "for epoch in range(2):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i , data in enumerate(trainloader , 0):\n",
    "        inputs , labels = data\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999 :\n",
    "            print( '[%d, %5d] loss: %.3f' %(epoch + 1 , i + 1, running_loss/1000)) \n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
